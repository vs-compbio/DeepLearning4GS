{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7be8c6-3c7e-4dd5-bb7d-f0e0b95a1710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install pandas\n",
    "#!pip3 install scikit-learn\n",
    "#!pip3 install scikeras[tensorflow]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92440057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/local/u6031121/300230/ipykernel_2670531/3226968778.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n",
      "2024-03-01 02:42:15.107052: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-01 02:42:15.107114: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-01 02:42:15.247302: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-01 02:42:15.466410: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "#from sklearn.neural_network import MLPRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.layers import Flatten, Conv1D, MaxPooling1D, LSTM\n",
    "from keras.activations import relu, elu, linear, softmax\n",
    "from keras.callbacks import EarlyStopping, Callback\n",
    "from tensorflow.keras.optimizers import Adam, Nadam\n",
    "from keras.losses import mean_squared_error, categorical_crossentropy, logcosh\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "#from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import time\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c615385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras_tuner\n",
    "from keras_tuner import RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "873e6368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n",
      "Device name: /physical_device:GPU:0\n",
      "Device name: /physical_device:GPU:1\n"
     ]
    }
   ],
   "source": [
    "# Check available devices\n",
    "devices = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "if len(devices) > 0:\n",
    "    print(\"GPU is available\")\n",
    "    for device in devices:\n",
    "        print(\"Device name:\", device.name)\n",
    "else:\n",
    "    print(\"No GPU is available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1d77917f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # processig data\n",
    "# def data_preprocess(dataset_trn,target_trn): \n",
    "#     # Scaled data\n",
    "#     min_max_scaler = MinMaxScaler(feature_range = (0,1))\n",
    "#     np_scaled = min_max_scaler.fit_transform(dataset_trn)\n",
    "#     X = pd.DataFrame(np_scaled)\n",
    "    \n",
    "#     target_edit = pd.Series(target_trn).values\n",
    "#     target_edit = target_edit.reshape(-1,1)\n",
    "#     np_scaled = min_max_scaler.fit_transform(target_edit)\n",
    "#     Y = pd.DataFrame(np_scaled)\n",
    "#     y_train = Y\n",
    "#     # Split data\n",
    "#     #from sklearn.model_selection import train_test_split\n",
    "#     #X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=42)\n",
    "      \n",
    "#     scaler = StandardScaler()\n",
    "#     # Fit only to the training data\n",
    "#     scaler.fit(X)\n",
    "        \n",
    "#     X_train = scaler.transform(X)\n",
    "#     #X_test = scaler.transform(X_test)\n",
    "    \n",
    "#     X_train = pd.DataFrame(X_train)\n",
    "#     #X_val = pd.DataFrame(X_test)\n",
    "#     #y_val = y_test\n",
    "#     return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a95389d-0f5a-4d7d-a1aa-1a35762ad2ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # processig data\n",
    "# def data_preprocess_tst(dataset_tst,target_tst): \n",
    "#     # Scaled data\n",
    "#     min_max_scaler = MinMaxScaler(feature_range = (0,1))\n",
    "#     np_scaled = min_max_scaler.fit_transform(dataset_tst)\n",
    "#     X_tst = pd.DataFrame(np_scaled)\n",
    "    \n",
    "#     target_edit = pd.Series(target_tst).values\n",
    "#     target_edit = target_edit.reshape(-1,1)\n",
    "#     np_scaled = min_max_scaler.fit_transform(target_edit)\n",
    "#     Y_tst = pd.DataFrame(np_scaled)\n",
    "#     y_test = Y_tst\n",
    "#     # Split data\n",
    "#    # from sklearn.model_selection import train_test_split\n",
    "#    # X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2, random_state=42)\n",
    "      \n",
    "#     scaler = StandardScaler()\n",
    "#     # Fit only to the training data\n",
    "#     scaler.fit(X_tst)\n",
    "        \n",
    "#     X_test = scaler.transform(X_tst)\n",
    "#     X_test = pd.DataFrame(X_test)\n",
    "    \n",
    "#     return X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae926107-adbe-4f1a-a54d-879be99a668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processig data\n",
    "def data_preprocess(dataset,target): \n",
    "    # Scaled data\n",
    "    min_max_scaler = MinMaxScaler(feature_range = (0,1))\n",
    "    np_scaled = min_max_scaler.fit_transform(dataset)\n",
    "    X = pd.DataFrame(np_scaled)\n",
    "    \n",
    "    target_edit = pd.Series(target).values\n",
    "    target_edit = target_edit.reshape(-1,1)\n",
    "    np_scaled = min_max_scaler.fit_transform(target_edit)\n",
    "    Y = pd.DataFrame(np_scaled)\n",
    "    # Split data\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.2)\n",
    "      \n",
    "    scaler = StandardScaler()\n",
    "    # Fit only to the training data\n",
    "    scaler.fit(X_train)\n",
    "        \n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test)\n",
    "    \n",
    "    X_train = pd.DataFrame(X_train)\n",
    "    X_test = pd.DataFrame(X_test)\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9f8d4484",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_correlation(pred, y_test, target):\n",
    "    pred = pred.reshape((-1,1))\n",
    "    target_edit = pd.Series(target).values\n",
    "    target_edit = target_edit.reshape(-1,1)\n",
    "    min_max_scaler = MinMaxScaler(feature_range = (0,1))\n",
    "    np_scaled = min_max_scaler.fit_transform(target_edit)\n",
    "    target_pred = min_max_scaler.inverse_transform(pred)\n",
    "    target_orig = min_max_scaler.inverse_transform(y_test)\n",
    "    target_orig = target_orig[:,0]\n",
    "    target_orig = pd.Series(target_orig)\n",
    "    target_pred = target_pred[:,0]\n",
    "    target_pred = pd.Series(target_pred)\n",
    "    cor1 = target_orig.corr(target_pred, method='pearson')\n",
    "    return cor1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0fe68916-3c86-43ba-90b8-ab71c5eb602b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dd20a84-7fd0-4f24-ba07-ef3ed731e8cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(396, 9999)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "329122cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    model = keras.Sequential()    \n",
    "    for i in range(1, hp.Int('num_layers', 2, 20)):\n",
    "        model.add(keras.layers.Dense(units=hp.Int('units_'+str(i),\n",
    "                                           min_value=32,\n",
    "                                           max_value=512, step=32),\n",
    "                              activation='relu', input_dim=9999))\n",
    "    model.add(keras.layers.Dense(1, activation=\"linear\"))\n",
    "    # Define the optimizer learning rate as a hyperparameter.\n",
    "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\")\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "        loss=\"mean_absolute_error\",\n",
    "        metrics=[\"mean_absolute_error\"])\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "85fa6e5e-345f-4e88-bbdb-e141b75f09aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-01 02:43:27.753696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22460 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:27:00.0, compute capability: 8.6\n",
      "2024-03-01 02:43:27.754677: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 22460 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:28:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "tuner = keras_tuner.Hyperband(\n",
    "    build_model,\n",
    "    objective=keras_tuner.Objective('val_mean_absolute_error','min'),\n",
    "    factor=3,\n",
    "    hyperband_iterations=5,\n",
    "    max_epochs=20,\n",
    "    overwrite=True,\n",
    "    #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "    directory='/uufs/chpc.utah.edu/common/home/akaundal-group3/Vishal/rough/',\n",
    "    max_consecutive_failed_trials=3,\n",
    "    project_name='Feb29_mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13639746-789d-4eb7-b672-84fcbabdeb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tuner = keras_tuner.BayesianOptimization(\n",
    "#     build_model,\n",
    "#     objective=keras_tuner.Objective('val_mean_absolute_error','min'),\n",
    "#     max_trials=50,\n",
    "#     executions_per_trial=4,\n",
    "#     overwrite=True,\n",
    "#     #distribution_strategy=tf.distribute.MirroredStrategy(),\n",
    "#     directory='/uufs/chpc.utah.edu/common/home/akaundal-group3/Vishal/rough/',\n",
    "#     max_consecutive_failed_trials=6,\n",
    "#     project_name='Feb29_mlp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fe8dbe-36a9-4a26-8e39-6da772e8cc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the search space including the number of epochs\n",
    "#tuner.search_space.update({'epochs': hp.Int('epochs', min_value=10, max_value=100, step=10)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8271d46b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 150 Complete [00h 00m 02s]\n",
      "val_mean_absolute_error: 0.23707647621631622\n",
      "\n",
      "Best val_mean_absolute_error So Far: 0.07773027569055557\n",
      "Total elapsed time: 00h 09m 33s\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('/uufs/chpc.utah.edu/common/home/akaundal-group3/Vishal/rough/Trn358_10kDL.csv', header=0)\n",
    "#data = pd.read_csv('/uufs/chpc.utah.edu/common/home/akaundal-group3/Vishal/NAM_dat.csv', header=0)\n",
    "dataset=data.iloc[:,1:10000]\n",
    "target=data.iloc[:, 10003]\n",
    "#preprocess data\n",
    "X_train, y_train, X_test, y_test = data_preprocess(dataset, target)\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "tuner.search(X_train, y_train, epochs=30, validation_split=0.15, callbacks=[early_stopping] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3a0f09b-2d7c-4776-b981-8255451b8be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the optimal hyperparameters\n",
    "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ad9c74f-8906-4e49-bc11-c53013c5dfd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras_tuner.src.engine.hyperparameters.hyperparameters.HyperParameters at 0x7f5ab0c1a010>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_hps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bff342fb-e054-4bdb-b501-f0a4acec31ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
      "layer is 384.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f\"\"\"\n",
    "The hyperparameter search is complete. The optimal number of units in the first densely-connected\n",
    "layer is {best_hps.get('units_19')}.\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "06829180-4842-4181-b79b-485956ed8172",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/uufs/chpc.utah.edu/common/home/akaundal-group3/Vishal/rough/Trn358_10kDL.csv', header=0)\n",
    "#data = pd.read_csv('/uufs/chpc.utah.edu/common/home/akaundal-group3/Vishal/NAM_dat.csv', header=0)\n",
    "dataset=data.iloc[:,1:10000]\n",
    "target=data.iloc[:, 10003]\n",
    "#preprocess data\n",
    "X_train, y_train, X_test, y_test = data_preprocess(dataset, target)\n",
    "\n",
    "early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
    "#tuner.search(X_train, y_train, epochs=30, validation_split=0.15, callbacks=[early_stopping] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "db33bf74-061e-484a-9319-d19411938f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "8/8 [==============================] - 3s 32ms/step - loss: 0.4987 - mean_absolute_error: 0.4987 - val_loss: 0.2061 - val_mean_absolute_error: 0.2061\n",
      "Epoch 2/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1242 - mean_absolute_error: 0.1242 - val_loss: 0.1068 - val_mean_absolute_error: 0.1068\n",
      "Epoch 3/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0925 - mean_absolute_error: 0.0925 - val_loss: 0.1236 - val_mean_absolute_error: 0.1236\n",
      "Epoch 4/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.1083 - mean_absolute_error: 0.1083 - val_loss: 0.1121 - val_mean_absolute_error: 0.1121\n",
      "Epoch 5/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0963 - mean_absolute_error: 0.0963 - val_loss: 0.1114 - val_mean_absolute_error: 0.1114\n",
      "Epoch 6/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0930 - mean_absolute_error: 0.0930 - val_loss: 0.1212 - val_mean_absolute_error: 0.1212\n",
      "Epoch 7/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0987 - mean_absolute_error: 0.0987 - val_loss: 0.1082 - val_mean_absolute_error: 0.1082\n",
      "Epoch 8/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0919 - mean_absolute_error: 0.0919 - val_loss: 0.1081 - val_mean_absolute_error: 0.1081\n",
      "Epoch 9/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0923 - mean_absolute_error: 0.0923 - val_loss: 0.1095 - val_mean_absolute_error: 0.1095\n",
      "Epoch 10/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0922 - mean_absolute_error: 0.0922 - val_loss: 0.1079 - val_mean_absolute_error: 0.1079\n",
      "Epoch 11/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0932 - mean_absolute_error: 0.0932 - val_loss: 0.1111 - val_mean_absolute_error: 0.1111\n",
      "Epoch 12/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0922 - mean_absolute_error: 0.0922 - val_loss: 0.1080 - val_mean_absolute_error: 0.1080\n",
      "Epoch 13/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0911 - mean_absolute_error: 0.0911 - val_loss: 0.1099 - val_mean_absolute_error: 0.1099\n",
      "Epoch 14/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0960 - mean_absolute_error: 0.0960 - val_loss: 0.1150 - val_mean_absolute_error: 0.1150\n",
      "Epoch 15/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1010 - mean_absolute_error: 0.1010 - val_loss: 0.1154 - val_mean_absolute_error: 0.1154\n",
      "Epoch 16/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0951 - mean_absolute_error: 0.0951 - val_loss: 0.1074 - val_mean_absolute_error: 0.1074\n",
      "Epoch 17/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0958 - mean_absolute_error: 0.0958 - val_loss: 0.1096 - val_mean_absolute_error: 0.1096\n",
      "Epoch 18/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1021 - mean_absolute_error: 0.1021 - val_loss: 0.1257 - val_mean_absolute_error: 0.1257\n",
      "Epoch 19/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0981 - mean_absolute_error: 0.0981 - val_loss: 0.1075 - val_mean_absolute_error: 0.1075\n",
      "Epoch 20/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0949 - mean_absolute_error: 0.0949 - val_loss: 0.1118 - val_mean_absolute_error: 0.1118\n",
      "Epoch 21/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0916 - mean_absolute_error: 0.0916 - val_loss: 0.1077 - val_mean_absolute_error: 0.1077\n",
      "Epoch 22/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0916 - mean_absolute_error: 0.0916 - val_loss: 0.1088 - val_mean_absolute_error: 0.1088\n",
      "Epoch 23/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0907 - mean_absolute_error: 0.0907 - val_loss: 0.1069 - val_mean_absolute_error: 0.1069\n",
      "Epoch 24/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0908 - mean_absolute_error: 0.0908 - val_loss: 0.1075 - val_mean_absolute_error: 0.1075\n",
      "Epoch 25/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0893 - mean_absolute_error: 0.0893 - val_loss: 0.1476 - val_mean_absolute_error: 0.1476\n",
      "Epoch 26/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0972 - mean_absolute_error: 0.0972 - val_loss: 0.1098 - val_mean_absolute_error: 0.1098\n",
      "Epoch 27/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0888 - mean_absolute_error: 0.0888 - val_loss: 0.1075 - val_mean_absolute_error: 0.1075\n",
      "Epoch 28/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0818 - mean_absolute_error: 0.0818 - val_loss: 0.1491 - val_mean_absolute_error: 0.1491\n",
      "Epoch 29/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.1016 - mean_absolute_error: 0.1016 - val_loss: 0.1099 - val_mean_absolute_error: 0.1099\n",
      "Epoch 30/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0853 - mean_absolute_error: 0.0853 - val_loss: 0.1094 - val_mean_absolute_error: 0.1094\n",
      "Epoch 31/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0862 - mean_absolute_error: 0.0862 - val_loss: 0.1167 - val_mean_absolute_error: 0.1167\n",
      "Epoch 32/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0844 - mean_absolute_error: 0.0844 - val_loss: 0.1137 - val_mean_absolute_error: 0.1137\n",
      "Epoch 33/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0821 - mean_absolute_error: 0.0821 - val_loss: 0.1317 - val_mean_absolute_error: 0.1317\n",
      "Epoch 34/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0767 - mean_absolute_error: 0.0767 - val_loss: 0.1207 - val_mean_absolute_error: 0.1207\n",
      "Epoch 35/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0694 - mean_absolute_error: 0.0694 - val_loss: 0.1615 - val_mean_absolute_error: 0.1615\n",
      "Epoch 36/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0906 - mean_absolute_error: 0.0906 - val_loss: 0.1091 - val_mean_absolute_error: 0.1091\n",
      "Epoch 37/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0795 - mean_absolute_error: 0.0795 - val_loss: 0.1154 - val_mean_absolute_error: 0.1154\n",
      "Epoch 38/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0737 - mean_absolute_error: 0.0737 - val_loss: 0.1036 - val_mean_absolute_error: 0.1036\n",
      "Epoch 39/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0705 - mean_absolute_error: 0.0705 - val_loss: 0.1290 - val_mean_absolute_error: 0.1290\n",
      "Epoch 40/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0910 - mean_absolute_error: 0.0910 - val_loss: 0.1133 - val_mean_absolute_error: 0.1133\n",
      "Epoch 41/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0682 - mean_absolute_error: 0.0682 - val_loss: 0.1246 - val_mean_absolute_error: 0.1246\n",
      "Epoch 42/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0673 - mean_absolute_error: 0.0673 - val_loss: 0.1189 - val_mean_absolute_error: 0.1189\n",
      "Epoch 43/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0666 - mean_absolute_error: 0.0666 - val_loss: 0.1173 - val_mean_absolute_error: 0.1173\n",
      "Epoch 44/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0589 - mean_absolute_error: 0.0589 - val_loss: 0.1231 - val_mean_absolute_error: 0.1231\n",
      "Epoch 45/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0672 - mean_absolute_error: 0.0672 - val_loss: 0.1082 - val_mean_absolute_error: 0.1082\n",
      "Epoch 46/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0607 - mean_absolute_error: 0.0607 - val_loss: 0.1140 - val_mean_absolute_error: 0.1140\n",
      "Epoch 47/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0622 - mean_absolute_error: 0.0622 - val_loss: 0.1214 - val_mean_absolute_error: 0.1214\n",
      "Epoch 48/50\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0599 - mean_absolute_error: 0.0599 - val_loss: 0.1329 - val_mean_absolute_error: 0.1329\n",
      "Epoch 49/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0693 - mean_absolute_error: 0.0693 - val_loss: 0.1101 - val_mean_absolute_error: 0.1101\n",
      "Epoch 50/50\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0635 - mean_absolute_error: 0.0635 - val_loss: 0.1316 - val_mean_absolute_error: 0.1316\n",
      "Best epoch: 38\n"
     ]
    }
   ],
   "source": [
    "# Build the model with the optimal hyperparameters and train it on the data for 50 epochs\n",
    "model = tuner.hypermodel.build(best_hps)\n",
    "history = model.fit(X_train, y_train, epochs=50, validation_split=0.2)\n",
    "\n",
    "val_acc_per_epoch = history.history['val_mean_absolute_error']\n",
    "best_epoch = val_acc_per_epoch.index(min(val_acc_per_epoch)) + 1\n",
    "print('Best epoch: %d' % (best_epoch,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3798abd2-d9c2-4a35-a693-5bd2cfa472f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "hypermodel = tuner.hypermodel.build(best_hps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "25bbcc13-cc2a-4326-9ed6-e22d4f52e241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/38\n",
      "8/8 [==============================] - 3s 33ms/step - loss: 0.4032 - mean_absolute_error: 0.4032 - val_loss: 1.6474 - val_mean_absolute_error: 1.6474\n",
      "Epoch 2/38\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.3844 - mean_absolute_error: 0.3844 - val_loss: 0.1078 - val_mean_absolute_error: 0.1078\n",
      "Epoch 3/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0938 - mean_absolute_error: 0.0938 - val_loss: 0.1076 - val_mean_absolute_error: 0.1076\n",
      "Epoch 4/38\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0962 - mean_absolute_error: 0.0962 - val_loss: 0.1108 - val_mean_absolute_error: 0.1108\n",
      "Epoch 5/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0918 - mean_absolute_error: 0.0918 - val_loss: 0.1071 - val_mean_absolute_error: 0.1071\n",
      "Epoch 6/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0919 - mean_absolute_error: 0.0919 - val_loss: 0.1098 - val_mean_absolute_error: 0.1098\n",
      "Epoch 7/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0912 - mean_absolute_error: 0.0912 - val_loss: 0.1084 - val_mean_absolute_error: 0.1084\n",
      "Epoch 8/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0981 - mean_absolute_error: 0.0981 - val_loss: 0.1089 - val_mean_absolute_error: 0.1089\n",
      "Epoch 9/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0914 - mean_absolute_error: 0.0914 - val_loss: 0.1070 - val_mean_absolute_error: 0.1070\n",
      "Epoch 10/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0932 - mean_absolute_error: 0.0932 - val_loss: 0.1070 - val_mean_absolute_error: 0.1070\n",
      "Epoch 11/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0911 - mean_absolute_error: 0.0911 - val_loss: 0.1069 - val_mean_absolute_error: 0.1069\n",
      "Epoch 12/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0907 - mean_absolute_error: 0.0907 - val_loss: 0.1175 - val_mean_absolute_error: 0.1175\n",
      "Epoch 13/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0913 - mean_absolute_error: 0.0913 - val_loss: 0.1064 - val_mean_absolute_error: 0.1064\n",
      "Epoch 14/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0992 - mean_absolute_error: 0.0992 - val_loss: 0.1213 - val_mean_absolute_error: 0.1213\n",
      "Epoch 15/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0921 - mean_absolute_error: 0.0921 - val_loss: 0.1055 - val_mean_absolute_error: 0.1055\n",
      "Epoch 16/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0944 - mean_absolute_error: 0.0944 - val_loss: 0.1077 - val_mean_absolute_error: 0.1077\n",
      "Epoch 17/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0948 - mean_absolute_error: 0.0948 - val_loss: 0.1069 - val_mean_absolute_error: 0.1069\n",
      "Epoch 18/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0973 - mean_absolute_error: 0.0973 - val_loss: 0.1175 - val_mean_absolute_error: 0.1175\n",
      "Epoch 19/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0977 - mean_absolute_error: 0.0977 - val_loss: 0.1087 - val_mean_absolute_error: 0.1087\n",
      "Epoch 20/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0946 - mean_absolute_error: 0.0946 - val_loss: 0.1120 - val_mean_absolute_error: 0.1120\n",
      "Epoch 21/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0922 - mean_absolute_error: 0.0922 - val_loss: 0.1069 - val_mean_absolute_error: 0.1069\n",
      "Epoch 22/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0921 - mean_absolute_error: 0.0921 - val_loss: 0.1108 - val_mean_absolute_error: 0.1108\n",
      "Epoch 23/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0932 - mean_absolute_error: 0.0932 - val_loss: 0.1078 - val_mean_absolute_error: 0.1078\n",
      "Epoch 24/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0915 - mean_absolute_error: 0.0915 - val_loss: 0.1080 - val_mean_absolute_error: 0.1080\n",
      "Epoch 25/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0920 - mean_absolute_error: 0.0920 - val_loss: 0.1086 - val_mean_absolute_error: 0.1086\n",
      "Epoch 26/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0915 - mean_absolute_error: 0.0915 - val_loss: 0.1072 - val_mean_absolute_error: 0.1072\n",
      "Epoch 27/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0951 - mean_absolute_error: 0.0951 - val_loss: 0.1120 - val_mean_absolute_error: 0.1120\n",
      "Epoch 28/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0974 - mean_absolute_error: 0.0974 - val_loss: 0.1079 - val_mean_absolute_error: 0.1079\n",
      "Epoch 29/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0995 - mean_absolute_error: 0.0995 - val_loss: 0.1076 - val_mean_absolute_error: 0.1076\n",
      "Epoch 30/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0925 - mean_absolute_error: 0.0925 - val_loss: 0.1121 - val_mean_absolute_error: 0.1121\n",
      "Epoch 31/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0909 - mean_absolute_error: 0.0909 - val_loss: 0.1083 - val_mean_absolute_error: 0.1083\n",
      "Epoch 32/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0954 - mean_absolute_error: 0.0954 - val_loss: 0.1134 - val_mean_absolute_error: 0.1134\n",
      "Epoch 33/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0942 - mean_absolute_error: 0.0942 - val_loss: 0.1085 - val_mean_absolute_error: 0.1085\n",
      "Epoch 34/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0925 - mean_absolute_error: 0.0925 - val_loss: 0.1083 - val_mean_absolute_error: 0.1083\n",
      "Epoch 35/38\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0913 - mean_absolute_error: 0.0913 - val_loss: 0.1093 - val_mean_absolute_error: 0.1093\n",
      "Epoch 36/38\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0937 - mean_absolute_error: 0.0937 - val_loss: 0.1069 - val_mean_absolute_error: 0.1069\n",
      "Epoch 37/38\n",
      "8/8 [==============================] - 0s 9ms/step - loss: 0.0938 - mean_absolute_error: 0.0938 - val_loss: 0.1091 - val_mean_absolute_error: 0.1091\n",
      "Epoch 38/38\n",
      "8/8 [==============================] - 0s 8ms/step - loss: 0.0928 - mean_absolute_error: 0.0928 - val_loss: 0.1094 - val_mean_absolute_error: 0.1094\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7f5bbe95b1d0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypermodel.fit(X_train, y_train, epochs=best_epoch, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6d0fe9a9-a92b-4fca-b483-26dfd19bcb5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f5bbcd68860> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "3/3 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = hypermodel.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7cd04c38-be75-436a-9618-549480531487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.08240123113220507"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor = cal_correlation(y_pred, y_test, target)\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259ed347-0b7e-48b6-b051-a6757211c5b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13eec27-3359-4b30-9938-8562f47f0d54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185bb85e-bdbe-4274-a21c-3c2dd1e8d9aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab71da68-ab68-4e27-9a45-d775f7734b6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbbc0db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "eval_result = hypermodel.evaluate(img_test, label_test)\n",
    "print(\"[test loss, test accuracy]:\", eval_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddfa326-173a-45e3-9280-0a52f312af99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda6e151-41ed-4133-a290-d38a53382bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e31a92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner.results_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ee14929-d66e-4897-8e70-a74505f86b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = tuner.oracle.get_best_trials(1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a81e2f0c-2b93-4954-b2bc-63e211b17094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_layers': 17,\n",
       " 'units_1': 320,\n",
       " 'lr': 0.004371994156211472,\n",
       " 'units_2': 288,\n",
       " 'units_3': 128,\n",
       " 'units_4': 192,\n",
       " 'units_5': 96,\n",
       " 'units_6': 128,\n",
       " 'units_7': 448,\n",
       " 'units_8': 64,\n",
       " 'units_9': 128,\n",
       " 'units_10': 288,\n",
       " 'units_11': 256,\n",
       " 'units_12': 416,\n",
       " 'units_13': 128,\n",
       " 'units_14': 192,\n",
       " 'units_15': 256,\n",
       " 'units_16': 384,\n",
       " 'units_17': 288,\n",
       " 'units_18': 128,\n",
       " 'units_19': 384,\n",
       " 'tuner/epochs': 20,\n",
       " 'tuner/initial_epoch': 7,\n",
       " 'tuner/bracket': 1,\n",
       " 'tuner/round': 1,\n",
       " 'tuner/trial_id': '0142'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_trial.hyperparameters.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37967c44-46b5-439e-b6e8-140d81ae508e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee59470",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = final_model_MLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d899f10a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.fit(X_train, y_train, epochs=50, batch_size=256, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fc52fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mae = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855105a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trial = tuner.oracle.get_best_trials(1)[0]\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_hyperparameters = best_trial.hyperparameters.values\n",
    "\n",
    "# Build the model using the best hyperparameters\n",
    "best_model = tuner.hypermodel.build(best_hyperparameters)\n",
    "\n",
    "# Train the model on the full training data\n",
    "best_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_val, y_val))\n",
    "\n",
    "# Make predictions on the test data\n",
    "test_predictions = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model on the test data if ground truth labels are available\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e62318",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_trial = tuner.oracle.get_best_trials(1)[0]\n",
    "best_hyperparameters = best_trial.hyperparameters.values\n",
    "num_layers = best_hyperparameters['num_layers']\n",
    "units_list = [best_hyperparameters[f'units_{i}'] for i in range(num_layers)]\n",
    "learningrate = best_hyperparameters['lr']\n",
    "#best_model = build_model(best_hyperparameters)\n",
    "best_hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6a04efc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 2ms/step\n",
      "Correlation coefficient: 0.06118766863633908\n"
     ]
    }
   ],
   "source": [
    "# Get predicted values from the best model\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Assuming `y_pred` contains your predicted values\n",
    "#print(\"Predicted values:\", y_pred)\n",
    "# Assuming `y_test` contains the true labels for the test data\n",
    "# Assuming `y_pred` contains the predicted values obtained from the best-fit model\n",
    "\n",
    "# Flatten the arrays if needed\n",
    "y_test_flat = y_test.values\n",
    "y_test_flat = y_test_flat.flatten()\n",
    "y_pred_flat = y_pred.flatten()\n",
    "\n",
    "# Calculate the correlation coefficient\n",
    "correlation = np.corrcoef(y_test_flat, y_pred_flat)[0, 1]\n",
    "\n",
    "# Print the correlation coefficient\n",
    "print(\"Correlation coefficient:\", correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1473ed7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06118759439915612"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cor = cal_correlation(y_pred, y_test, target)\n",
    "cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "df6fb2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate average of items in a list\n",
    "def Average(lst): \n",
    "    return sum(lst) / len(lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5516ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #start time\n",
    "    start = time.time()\n",
    "    \n",
    "    #data = pd.read_csv('/uufs/chpc.utah.edu/common/home/akaundal-group3/Vishal/NAM_dat.csv', header=0)\n",
    "    dataset=data.iloc[:,19:]\n",
    "    target=data.iloc[:, 4]\n",
    "    \n",
    "    #preprocess data\n",
    "    X_train, y_train, X_test, y_test = data_preprocess(dataset, target)\n",
    "    \n",
    "    #store all cor and accuracy values for mlp\n",
    "    cor_mlp = []\n",
    "    acc_mlp = []\n",
    "    #store all cor and accuracy values for cnn\n",
    "    cor_cnn = []\n",
    "    acc_cnn = []\n",
    "    \n",
    "    #200 iterations\n",
    "    for i in range(10):\n",
    "        # Multilayer perceptron\n",
    "        print('MLP:')\n",
    "        scores_mlp, pred_mlp = multi_layer_perceptron(X_train, y_train, X_test, y_test)\n",
    "        cor_m = cal_correlation(pred_mlp, y_test, target)\n",
    "        print('Correlation for MLP ',cor_m)\n",
    "        cor_mlp.append(cor_m)\n",
    "        acc_mlp.append(scores_mlp)\n",
    "    \n",
    "        # CNN\n",
    "        #print('CNN:')\n",
    "       # scores_cnn, pred_cnn = cnn(X_train, y_train, X_test, y_test)\n",
    "       # cor_c = cal_correlation(pred_cnn, y_test, target)\n",
    "       # print('Correlation for CNN ',cor_c)\n",
    "       # cor_cnn.append(cor_c)\n",
    "       # acc_cnn.append(scores_mlp)\n",
    "    \n",
    "    #average values\n",
    "    print(\"Average accuracy for MLP: \", Average(acc_mlp))\n",
    "    print(\"Average correlation for MLP: \", Average(cor_mlp))\n",
    "   # print(\"Average accuracy for CNN: \", Average(acc_cnn))\n",
    "   # print(\"Average correlation for CNN: \", Average(cor_cnn))\n",
    "    \n",
    "    #end time\n",
    "    end = time.time()\n",
    "    print(\"Time elapsed: \",end - start)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26c9744",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65abec4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dcad20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8882ee86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869e5260",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa86f7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eecf22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c85b04",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cc4e33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174db251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bd6dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_trials = tuner.oracle.get_best_trials(1)\n",
    "best_trial = best_trials[0]  # Assuming you want information about the top best trial\n",
    "\n",
    "# Accessing information about the best trial\n",
    "best_hyperparameters = best_trial.hyperparameters.values\n",
    "best_model_dir = best_trial.trial_id  # Directory where the best model checkpoints are saved\n",
    "best_score = best_trial.score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d77182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.add(keras.layers.Flatten())\n",
    "#     model.add(\n",
    "#         keras.layers.Dense(\n",
    "#             # Tune number of units.\n",
    "#             units=hp.Int(\"units\", min_value=32, max_value=512, step=32),\n",
    "#             # Tune the activation function to use.\n",
    "#             activation=hp.Choice(\"activation\", [\"relu\",\"tanh\"]),\n",
    "#         )\n",
    "#     )\n",
    "#     # Tune whether to use dropout.\n",
    "#     if hp.Boolean(\"dropout\"):\n",
    "#         model.add(keras.layers.Dropout(rate=0.25))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
